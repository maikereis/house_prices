{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/header.png\"></img>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 843,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2 \n",
    "\n",
    "import re\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas.api.types import CategoricalDtype\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "from statsmodels.graphics.gofplots import qqplot\n",
    "from scipy.stats import norm, skew, boxcox, normaltest, boxcox_normmax\n",
    "from scipy.special import boxcox1p\n",
    "\n",
    "\n",
    "from sklearn import set_config\n",
    "set_config(display='diagram')  \n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "\n",
    "from sklearn.model_selection import KFold, cross_val_score, train_test_split\n",
    "\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn.preprocessing import RobustScaler, StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "from sklearn.compose import make_column_transformer, make_column_selector\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "from category_encoders.cat_boost import CatBoostEncoder\n",
    "\n",
    "# Flag to plot graphics or not\n",
    "# Prints slow the notebook execution.\n",
    "PLOT = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 844,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Download data from kaggle\n",
    "# from util import get_data\n",
    "# get_data()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 845,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_relationship(data, title):\n",
    "    width = 8\n",
    "    if len(data) > 70:\n",
    "        width = 12\n",
    "    fig, ax = plt.subplots(figsize=(width, 4))\n",
    "    g = sns.barplot(x=data.index, y=data, ax=ax)\n",
    "    ax.tick_params(axis=\"x\", rotation=-90)\n",
    "    ax.set_ylim(1.2 * data.min(), 1.2 * data.max())\n",
    "    g.set_title(title)\n",
    "    plt.tight_layout()\n",
    "\n",
    "\n",
    "def plot_variance(pca):\n",
    "    # Create figure\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(8,4))\n",
    "    n = pca.n_components_\n",
    "    grid = np.arange(1, n + 1)\n",
    "    # Explained variance\n",
    "    evr = pca.explained_variance_ratio_\n",
    "    axs[0].bar(grid, evr)\n",
    "    axs[0].set(xlabel=\"Component\", title=\"% Explained Variance\", ylim=(0.0, 1.0))\n",
    "    # Cumulative Variance\n",
    "    cv = np.cumsum(evr)\n",
    "    axs[1].plot(np.r_[0, grid], np.r_[0, cv], \"o-\")\n",
    "    axs[1].set(xlabel=\"Component\", title=\"% Cumulative Variance\", ylim=(0.0, 1.0))\n",
    "\n",
    "\n",
    "def corrplot(df, method=\"pearson\", annot=True, **kwargs):\n",
    "    sns.clustermap(\n",
    "        df.corr(method),\n",
    "        vmin=-1.0,\n",
    "        vmax=1.0,\n",
    "        cmap=\"icefire\",\n",
    "        method=\"complete\",\n",
    "        annot=annot,\n",
    "        **kwargs,\n",
    "    )\n",
    "\n",
    "\n",
    "def get_missing(df, percent=False):\n",
    "    if percent:\n",
    "        missing = (df.isnull().sum() * 100 / df.isnull().count()).sort_values(\n",
    "            ascending=False\n",
    "        )\n",
    "    else:\n",
    "        missing = df.isnull().sum()\n",
    "\n",
    "    missing = missing[missing > 0].sort_values(ascending=False)\n",
    "    return missing\n",
    "\n",
    "\n",
    "def get_rsquares(X, y):\n",
    "\n",
    "    X = X.copy()\n",
    "\n",
    "    model = LinearRegression()\n",
    "\n",
    "    for col in X.select_dtypes(\"object\"):\n",
    "        X[col], _ = X[col].factorize()\n",
    "\n",
    "    rsquares = {}\n",
    "    for col in X.columns:\n",
    "        X_, y_ = pd.get_dummies(X[col]), y\n",
    "        model.fit(X_, y_)\n",
    "        r2 = model.score(X_, y_)\n",
    "        rsquares[col] = r2\n",
    "    rsquares = pd.Series(rsquares)\n",
    "    return rsquares\n",
    "\n",
    "\n",
    "def make_mi_scores(X, y):\n",
    "    X = X.copy()\n",
    "\n",
    "    if isinstance(X, pd.DataFrame):\n",
    "        for colname in X.select_dtypes(\"object\"):\n",
    "            X[colname], _ = X[colname].factorize()\n",
    "        for colname in X.select_dtypes(\"category\"):\n",
    "            X[colname] = X[colname].cat.codes\n",
    "\n",
    "    # All discrete features should now have integer dtypes\n",
    "    discrete_features = [pd.api.types.is_integer_dtype(t) for t in X.dtypes]\n",
    "    mi_scores = mutual_info_regression(\n",
    "        X, y, discrete_features=discrete_features, random_state=0\n",
    "    )\n",
    "    mi_scores = pd.Series(mi_scores, name=\"MI Scores\", index=X.columns)\n",
    "    mi_scores = mi_scores.sort_values(ascending=False)\n",
    "    return mi_scores\n",
    "\n",
    "\n",
    "def custom_boxplot(X, y, **kwargs):\n",
    "    sns.boxplot(x=X, y=y)\n",
    "    x = plt.xticks(rotation=90)\n",
    "    plt.tight_layout()\n",
    "\n",
    "\n",
    "def get_low_cardinality(df, threshold):\n",
    "    low_card = {\n",
    "        col: len(df[col].unique()) for col in df if (len(df[col].unique())) <= threshold\n",
    "    }\n",
    "    return low_card\n",
    "\n",
    "\n",
    "def get_high_cardinality(df, threshold):\n",
    "    low_card = {\n",
    "        col: len(df[col].unique()) for col in df if (len(df[col].unique())) > threshold\n",
    "    }\n",
    "    return low_card\n",
    "\n",
    "\n",
    "def score_dataset(X, y, model=XGBRegressor()):\n",
    "    X = X.copy()\n",
    "    if isinstance(X, pd.DataFrame):\n",
    "        for colname in X.select_dtypes([\"category\"]):\n",
    "            X[colname] = X[colname].cat.codes\n",
    "    # Metric for Housing competition is RMSLE (Root Mean Squared Log Error)\n",
    "    log_y = np.log(y)\n",
    "    scores = np.sqrt(-cross_val_score(model, X, log_y, cv=5, scoring=\"neg_mean_squared_error\"))\n",
    "    return scores.mean()\n",
    "\n",
    "def score_norm_dataset(X, y, model=XGBRegressor()):\n",
    "    if isinstance(X, pd.DataFrame):\n",
    "        for colname in X.select_dtypes([\"category\"]):\n",
    "            X[colname] = X[colname].cat.codes\n",
    "            \n",
    "    rmsle = np.sqrt(-cross_val_score(model, X, y, cv=7, scoring=\"neg_mean_squared_error\"))\n",
    "    return np.mean(rmsle)\n",
    "\n",
    "def rmsle(log_y, log_y_pred):\n",
    "    return np.sqrt(mean_squared_error(log_y, log_y_pred))\n",
    "\n",
    "def drop_uninformative(df, mi_scores):\n",
    "    return df.loc[:, mi_scores > 0.0]\n",
    "\n",
    "\n",
    "def generate_submission_file(X_test, y_pred, score):\n",
    "    # Concatenate the predictions in a dataset\n",
    "    output = pd.DataFrame(y_pred, index=np.arange(1461,2920), columns=[\"SalePrice\"])\n",
    "\n",
    "    output[\"Id\"] = output.index\n",
    "\n",
    "    # Generate a file name with datetime info\n",
    "    file_name = datetime.datetime.today().strftime(\n",
    "        f\"%Y_%m_%d__%H_%M_%S_with_score__{np.round(score,6)}\"\n",
    "    )\n",
    "    # Generate the submission file\n",
    "    output.to_csv(f\"output/{file_name}__.csv\", index=False)\n",
    "\n",
    "\n",
    "def plot_interactions(data, X, hue, y=\"SalePrice\"):\n",
    "    sns.lmplot(\n",
    "        data=data,\n",
    "        x=X,\n",
    "        y=y,\n",
    "        hue=hue,\n",
    "        col=hue,\n",
    "        scatter_kws={\"edgecolor\": \"w\"},\n",
    "        col_wrap=3,\n",
    "        height=2,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Exploratoy Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.1 Data Preview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 846,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"data/train.csv\", index_col=\"Id\")\n",
    "X, y = train.drop(\"SalePrice\", axis=1), train[\"SalePrice\"]\n",
    "X_test = pd.read_csv(\"data/test.csv\", index_col=\"Id\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 847,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>LotConfig</th>\n",
       "      <th>...</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>FR2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 80 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "Id                                                                    \n",
       "1           60       RL         65.0     8450   Pave   NaN      Reg   \n",
       "2           20       RL         80.0     9600   Pave   NaN      Reg   \n",
       "\n",
       "   LandContour Utilities LotConfig  ... PoolArea PoolQC Fence MiscFeature  \\\n",
       "Id                                  ...                                     \n",
       "1          Lvl    AllPub    Inside  ...        0    NaN   NaN         NaN   \n",
       "2          Lvl    AllPub       FR2  ...        0    NaN   NaN         NaN   \n",
       "\n",
       "   MiscVal MoSold  YrSold  SaleType  SaleCondition  SalePrice  \n",
       "Id                                                             \n",
       "1        0      2    2008        WD         Normal     208500  \n",
       "2        0      5    2007        WD         Normal     181500  \n",
       "\n",
       "[2 rows x 80 columns]"
      ]
     },
     "execution_count": 847,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 848,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1460 entries, 1 to 1460\n",
      "Data columns (total 80 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   MSSubClass     1460 non-null   int64  \n",
      " 1   MSZoning       1460 non-null   object \n",
      " 2   LotFrontage    1201 non-null   float64\n",
      " 3   LotArea        1460 non-null   int64  \n",
      " 4   Street         1460 non-null   object \n",
      " 5   Alley          91 non-null     object \n",
      " 6   LotShape       1460 non-null   object \n",
      " 7   LandContour    1460 non-null   object \n",
      " 8   Utilities      1460 non-null   object \n",
      " 9   LotConfig      1460 non-null   object \n",
      " 10  LandSlope      1460 non-null   object \n",
      " 11  Neighborhood   1460 non-null   object \n",
      " 12  Condition1     1460 non-null   object \n",
      " 13  Condition2     1460 non-null   object \n",
      " 14  BldgType       1460 non-null   object \n",
      " 15  HouseStyle     1460 non-null   object \n",
      " 16  OverallQual    1460 non-null   int64  \n",
      " 17  OverallCond    1460 non-null   int64  \n",
      " 18  YearBuilt      1460 non-null   int64  \n",
      " 19  YearRemodAdd   1460 non-null   int64  \n",
      " 20  RoofStyle      1460 non-null   object \n",
      " 21  RoofMatl       1460 non-null   object \n",
      " 22  Exterior1st    1460 non-null   object \n",
      " 23  Exterior2nd    1460 non-null   object \n",
      " 24  MasVnrType     1452 non-null   object \n",
      " 25  MasVnrArea     1452 non-null   float64\n",
      " 26  ExterQual      1460 non-null   object \n",
      " 27  ExterCond      1460 non-null   object \n",
      " 28  Foundation     1460 non-null   object \n",
      " 29  BsmtQual       1423 non-null   object \n",
      " 30  BsmtCond       1423 non-null   object \n",
      " 31  BsmtExposure   1422 non-null   object \n",
      " 32  BsmtFinType1   1423 non-null   object \n",
      " 33  BsmtFinSF1     1460 non-null   int64  \n",
      " 34  BsmtFinType2   1422 non-null   object \n",
      " 35  BsmtFinSF2     1460 non-null   int64  \n",
      " 36  BsmtUnfSF      1460 non-null   int64  \n",
      " 37  TotalBsmtSF    1460 non-null   int64  \n",
      " 38  Heating        1460 non-null   object \n",
      " 39  HeatingQC      1460 non-null   object \n",
      " 40  CentralAir     1460 non-null   object \n",
      " 41  Electrical     1459 non-null   object \n",
      " 42  1stFlrSF       1460 non-null   int64  \n",
      " 43  2ndFlrSF       1460 non-null   int64  \n",
      " 44  LowQualFinSF   1460 non-null   int64  \n",
      " 45  GrLivArea      1460 non-null   int64  \n",
      " 46  BsmtFullBath   1460 non-null   int64  \n",
      " 47  BsmtHalfBath   1460 non-null   int64  \n",
      " 48  FullBath       1460 non-null   int64  \n",
      " 49  HalfBath       1460 non-null   int64  \n",
      " 50  BedroomAbvGr   1460 non-null   int64  \n",
      " 51  KitchenAbvGr   1460 non-null   int64  \n",
      " 52  KitchenQual    1460 non-null   object \n",
      " 53  TotRmsAbvGrd   1460 non-null   int64  \n",
      " 54  Functional     1460 non-null   object \n",
      " 55  Fireplaces     1460 non-null   int64  \n",
      " 56  FireplaceQu    770 non-null    object \n",
      " 57  GarageType     1379 non-null   object \n",
      " 58  GarageYrBlt    1379 non-null   float64\n",
      " 59  GarageFinish   1379 non-null   object \n",
      " 60  GarageCars     1460 non-null   int64  \n",
      " 61  GarageArea     1460 non-null   int64  \n",
      " 62  GarageQual     1379 non-null   object \n",
      " 63  GarageCond     1379 non-null   object \n",
      " 64  PavedDrive     1460 non-null   object \n",
      " 65  WoodDeckSF     1460 non-null   int64  \n",
      " 66  OpenPorchSF    1460 non-null   int64  \n",
      " 67  EnclosedPorch  1460 non-null   int64  \n",
      " 68  3SsnPorch      1460 non-null   int64  \n",
      " 69  ScreenPorch    1460 non-null   int64  \n",
      " 70  PoolArea       1460 non-null   int64  \n",
      " 71  PoolQC         7 non-null      object \n",
      " 72  Fence          281 non-null    object \n",
      " 73  MiscFeature    54 non-null     object \n",
      " 74  MiscVal        1460 non-null   int64  \n",
      " 75  MoSold         1460 non-null   int64  \n",
      " 76  YrSold         1460 non-null   int64  \n",
      " 77  SaleType       1460 non-null   object \n",
      " 78  SaleCondition  1460 non-null   object \n",
      " 79  SalePrice      1460 non-null   int64  \n",
      "dtypes: float64(3), int64(34), object(43)\n",
      "memory usage: 923.9+ KB\n"
     ]
    }
   ],
   "source": [
    "train.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 849,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.astype({\"MSSubClass\": object, \"OverallQual\": object, \"OverallCond\":object, \"MoSold\": object})\n",
    "categorical_data = train.select_dtypes('object')\n",
    "numerical_data = train.select_dtypes('number')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 850,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>LotConfig</th>\n",
       "      <th>LandSlope</th>\n",
       "      <th>Neighborhood</th>\n",
       "      <th>...</th>\n",
       "      <th>GarageFinish</th>\n",
       "      <th>GarageQual</th>\n",
       "      <th>GarageCond</th>\n",
       "      <th>PavedDrive</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>CollgCr</td>\n",
       "      <td>...</td>\n",
       "      <td>RFn</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>FR2</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>Veenker</td>\n",
       "      <td>...</td>\n",
       "      <td>RFn</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   MSSubClass MSZoning Street Alley LotShape LandContour Utilities LotConfig  \\\n",
       "Id                                                                             \n",
       "1          60       RL   Pave   NaN      Reg         Lvl    AllPub    Inside   \n",
       "2          20       RL   Pave   NaN      Reg         Lvl    AllPub       FR2   \n",
       "\n",
       "   LandSlope Neighborhood  ... GarageFinish GarageQual GarageCond PavedDrive  \\\n",
       "Id                         ...                                                 \n",
       "1        Gtl      CollgCr  ...          RFn         TA         TA          Y   \n",
       "2        Gtl      Veenker  ...          RFn         TA         TA          Y   \n",
       "\n",
       "   PoolQC Fence MiscFeature MoSold SaleType SaleCondition  \n",
       "Id                                                         \n",
       "1     NaN   NaN         NaN      2       WD        Normal  \n",
       "2     NaN   NaN         NaN      5       WD        Normal  \n",
       "\n",
       "[2 rows x 47 columns]"
      ]
     },
     "execution_count": 850,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_data.head(2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numerical discrete variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 851,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>MasVnrArea</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>BsmtFinSF2</th>\n",
       "      <th>BsmtUnfSF</th>\n",
       "      <th>TotalBsmtSF</th>\n",
       "      <th>1stFlrSF</th>\n",
       "      <th>...</th>\n",
       "      <th>GarageArea</th>\n",
       "      <th>WoodDeckSF</th>\n",
       "      <th>OpenPorchSF</th>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>2003</td>\n",
       "      <td>2003</td>\n",
       "      <td>196.0</td>\n",
       "      <td>706</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>856</td>\n",
       "      <td>856</td>\n",
       "      <td>...</td>\n",
       "      <td>548</td>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2008</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>1976</td>\n",
       "      <td>1976</td>\n",
       "      <td>0.0</td>\n",
       "      <td>978</td>\n",
       "      <td>0</td>\n",
       "      <td>284</td>\n",
       "      <td>1262</td>\n",
       "      <td>1262</td>\n",
       "      <td>...</td>\n",
       "      <td>460</td>\n",
       "      <td>298</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2007</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    LotFrontage  LotArea  YearBuilt  YearRemodAdd  MasVnrArea  BsmtFinSF1  \\\n",
       "Id                                                                          \n",
       "1          65.0     8450       2003          2003       196.0         706   \n",
       "2          80.0     9600       1976          1976         0.0         978   \n",
       "\n",
       "    BsmtFinSF2  BsmtUnfSF  TotalBsmtSF  1stFlrSF  ...  GarageArea  WoodDeckSF  \\\n",
       "Id                                                ...                           \n",
       "1            0        150          856       856  ...         548           0   \n",
       "2            0        284         1262      1262  ...         460         298   \n",
       "\n",
       "    OpenPorchSF  EnclosedPorch  3SsnPorch  ScreenPorch  PoolArea  MiscVal  \\\n",
       "Id                                                                          \n",
       "1            61              0          0            0         0        0   \n",
       "2             0              0          0            0         0        0   \n",
       "\n",
       "    YrSold  SalePrice  \n",
       "Id                     \n",
       "1     2008     208500  \n",
       "2     2007     181500  \n",
       "\n",
       "[2 rows x 33 columns]"
      ]
     },
     "execution_count": 851,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numerical_data.head(2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.2 Missing Data <a id='missing_data'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset has some columns with considerable number os missing values:\n",
    "\n",
    "&emsp;&emsp;__PoolQC, MiscFeature, Alley, Fence, FireplaceQu__ columns have more than 50 % of values missing.\\\n",
    "&emsp;&emsp;__Frontage__ has roughly 15 % of missing data.\\\n",
    "&emsp;&emsp;__Garage, Bsmt, and MasVnr__ have between 2% and 3% of missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 852,
   "metadata": {},
   "outputs": [],
   "source": [
    "if PLOT:\n",
    "    plot_relationship(get_missing(X, True), \"Missing Values in Train Dataset (%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.3 Mutual Information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MI score can give us an idea of how much information about the target _SalePrice_ each feature has. The farther from zero it is, the more information it can provide about the target. In this dataset, the features **OverallQual**, **Neighborhood**, **GrLivArea**, **GarageArea**, **YearBuilt** and **ExternalQual** are good candidates for predictors to **SalePrice**. On the other hand, **MoSold** (Month Sold) and **PoolIQC** (Pool Quality) don**t seem to be good predictors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 853,
   "metadata": {},
   "outputs": [],
   "source": [
    "if PLOT:\n",
    "    mi_scores = make_mi_scores(X.fillna(0), y)\n",
    "    plot_relationship(mi_scores, \"Mutual Information of Each Feature\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.4 Correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correlation is a measures of **linear** association between two variables. Positive values indicate direct relationship, negative values indicate a inverse relationship."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 854,
   "metadata": {},
   "outputs": [],
   "source": [
    "if PLOT:\n",
    "    correlations = numerical_data.corrwith(numerical_data['SalePrice']).drop('SalePrice').sort_values(ascending=False)\n",
    "    plot_relationship(correlations, \"Correlations of Each Feature with SalePrice\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **OverallQual**, **GrLivArea**, **GarageCars**, and **TotalBsmtSF** from moderate to strong correlation with **SalePrice**\n",
    "\n",
    "Despite Correlation represents the linear association, different distribuitions of data can have the same correlation without the data even following the regression curve. So we need to take a look to the regression graphics and check if the correlations are good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 855,
   "metadata": {},
   "outputs": [],
   "source": [
    "if PLOT:\n",
    "    fg = pd.melt(\n",
    "        numerical_data.fillna(0),\n",
    "        id_vars=[\"SalePrice\"],\n",
    "    )\n",
    "    g = sns.FacetGrid(\n",
    "        fg, col=\"variable\", col_wrap=4, sharex=False, sharey=False, height=3\n",
    "    )\n",
    "    g.map(sns.regplot, \"value\", \"SalePrice\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see **LotArea**, **MiscVal**, and **ScreenPorch** correlations are not reliable, although the correlation has values different from 0, the data distribution doesn't follow the regression line."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.5 R-square"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Such as correlation, we can measure the degree of association between categorical variables and hour target. through the R-square, we can measure how much variation of **SalePrice** is explained by hour features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 856,
   "metadata": {},
   "outputs": [],
   "source": [
    "if PLOT:\n",
    "    rsquares = get_rsquares(categorical_data, y).sort_values(ascending=False)\n",
    "    plot_relationship(rsquares, \"Variation of 'SalePrice' explained by each feature\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**OverallQual**, **Neighbornhood**, and **ExerQual** explain more than 50% from variation of **SalePrice**. Lets take a look to theese categorical variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 857,
   "metadata": {},
   "outputs": [],
   "source": [
    "if PLOT:\n",
    "    f = pd.melt(\n",
    "        categorical_data.join(numerical_data['SalePrice']).fillna(\"None\"),\n",
    "        id_vars=[\"SalePrice\"],\n",
    "    )\n",
    "    g = sns.FacetGrid(\n",
    "        f, col=\"variable\", col_wrap=4, sharex=False, sharey=False, height=3\n",
    "    )\n",
    "    g.map(custom_boxplot, \"value\", \"SalePrice\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.6 Visualising Interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 858,
   "metadata": {},
   "outputs": [],
   "source": [
    "if PLOT:\n",
    "    plot_interactions(train, 'GrLivArea', 'BedroomAbvGr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 859,
   "metadata": {},
   "outputs": [],
   "source": [
    "if PLOT:\n",
    "    plot_interactions(train, 'GrLivArea', 'BldgType')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 860,
   "metadata": {},
   "outputs": [],
   "source": [
    "if PLOT:\n",
    "    plot_interactions(train, 'GrLivArea', 'GarageCars')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 861,
   "metadata": {},
   "outputs": [],
   "source": [
    "if PLOT:\n",
    "    plot_interactions(train, 'TotalBsmtSF', 'BsmtCond')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 862,
   "metadata": {},
   "outputs": [],
   "source": [
    "if PLOT:\n",
    "    plot_interactions(numerical_data, 'GrLivArea', 'KitchenAbvGr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Prepare Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.1 Fix Typos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 863,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class FixTypos\n",
    "class FixTypos:\n",
    "    def __init__(self):\n",
    "        return None\n",
    "\n",
    "    def __repr__(self):\n",
    "        return \"FixTypos()\"\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "\n",
    "        self.X = X.copy()\n",
    "        self.X.Exterior2nd = self.X.Exterior2nd.replace(\"Brk Cmn\", \"BrkComm\")\n",
    "        self.X.Exterior2nd = self.X.Exterior2nd.replace(\"CmentBd\", \"CemntBd\")\n",
    "        self.X.Exterior2nd = self.X.Exterior2nd.replace(\"Wd Shng\", \"Wd Sdng\")\n",
    "        self.X.BldgType = self.X.BldgType.replace(\"Twnhs\", \"TwnhsI\")\n",
    "        self.X.BldgType = self.X.BldgType.replace(\"2fmCon\", \"2FmCon\")\n",
    "        self.X.BldgType = self.X.BldgType.replace(\"Duplex\", \"Duplx\")\n",
    "        self.X.rename(\n",
    "            columns={\n",
    "                \"1stFlrSF\": \"FirstFlrSF\",\n",
    "                \"2ndFlrSF\": \"SecondFlrSF\",\n",
    "                \"3SsnPorch\": \"Threeseasonporch\",\n",
    "            },\n",
    "            inplace=True,\n",
    "        )\n",
    "\n",
    "        return self.X\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To fix typos and some columns names i'll use the class FixTypos that perform the following replacements:\n",
    "\n",
    "        'Brk Cmn' by 'BrkComm'\n",
    "        'CmentBd' by 'CemntBd'\n",
    "        'Wd Shng' by 'Wd Sdng'\n",
    "        'Twnhs' by 'TwnhsI'\n",
    "        '2fmCon' by '2FmCon'\n",
    "        'Duplex' by 'Duplx'\n",
    "\n",
    "and rename the columns;\n",
    "\n",
    "        \"1stFlrSF\" to \"FirstFlrSF\"\n",
    "        \"2ndFlrSF\" to \"SecondFlrSF\"\n",
    "        \"3SsnPorch\" to \"Threeseasonporch\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.2 Categorize Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ordinal categorical will be encoded as ordered **category** type. Unordered categorical data will be encoded as **category** but without any order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 864,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical Data Dictionaries\n",
    "# Unordered categorical columns\n",
    "unordered_levels = {\n",
    "    \"MSSubClass\": [20, 30, 40, 45, 50, 60, 70, 75, 80, 85, 90, 120, 150, 160, 180, 190],\n",
    "    \"MSZoning\": [\"A\", \"C (all)\", \"FV\", \"I\", \"RH\", \"RL\", \"RP\", \"RM\"],\n",
    "    \"Street\": [\"Grvl\", \"Pave\"],\n",
    "    \"Alley\": [\"Grvl\", \"Pave\", \"None\"],\n",
    "    \"LandContour\": [\"Lvl\", \"Bnk\", \"HLS\", \"Low\"],\n",
    "    \"LotConfig\": [\"Inside\", \"Corner\", \"CulDSac\", \"FR2\", \"FR3\"],\n",
    "    \"Neighborhood\": [\n",
    "        \"Blmngtn\",\n",
    "        \"Blueste\",\n",
    "        \"BrDale\",\n",
    "        \"BrkSide\",\n",
    "        \"ClearCr\",\n",
    "        \"CollgCr\",\n",
    "        \"Crawfor\",\n",
    "        \"Edwards\",\n",
    "        \"Gilbert\",\n",
    "        \"IDOTRR\",\n",
    "        \"MeadowV\",\n",
    "        \"Mitchel\",\n",
    "        \"NAmes\",\n",
    "        \"NoRidge\",\n",
    "        \"NPkVill\",\n",
    "        \"NridgHt\",\n",
    "        \"NWAmes\",\n",
    "        \"OldTown\",\n",
    "        \"SWISU\",\n",
    "        \"Sawyer\",\n",
    "        \"SawyerW\",\n",
    "        \"Somerst\",\n",
    "        \"StoneBr\",\n",
    "        \"Timber\",\n",
    "        \"Veenker\",\n",
    "    ],\n",
    "    \"Condition1\": [\n",
    "        \"Artery\",\n",
    "        \"Feedr\",\n",
    "        \"Norm\",\n",
    "        \"RRNn\",\n",
    "        \"RRAn\",\n",
    "        \"PosN\",\n",
    "        \"PosA\",\n",
    "        \"RRNe\",\n",
    "        \"RRAe\",\n",
    "    ],\n",
    "    \"Condition2\": [\n",
    "        \"Artery\",\n",
    "        \"Feedr\",\n",
    "        \"Norm\",\n",
    "        \"RRNn\",\n",
    "        \"RRAn\",\n",
    "        \"PosN\",\n",
    "        \"PosA\",\n",
    "        \"RRNe\",\n",
    "        \"RRAe\",\n",
    "    ],\n",
    "    \"BldgType\": [\"1Fam\", \"2FmCon\", \"Duplx\", \"TwnhsE\", \"TwnhsI\"],\n",
    "    \"HouseStyle\": [\n",
    "        \"1Story\",\n",
    "        \"1.5Fin\",\n",
    "        \"1.5Unf\",\n",
    "        \"2Story\",\n",
    "        \"2.5Fin\",\n",
    "        \"2.5Unf\",\n",
    "        \"SFoyer\",\n",
    "        \"SLvl\",\n",
    "    ],\n",
    "    \"RoofStyle\": [\"Flat\", \"Gable\", \"Gambrel\", \"Hip\", \"Mansard\", \"Shed\"],\n",
    "    \"RoofMatl\": [\n",
    "        \"ClyTile\",\n",
    "        \"CompShg\",\n",
    "        \"Membran\",\n",
    "        \"Metal\",\n",
    "        \"Roll\",\n",
    "        \"Tar&Grv\",\n",
    "        \"WdShake\",\n",
    "        \"WdShngl\",\n",
    "    ],\n",
    "    \"Exterior1st\": [\n",
    "        \"AsbShng\",\n",
    "        \"AsphShn\",\n",
    "        \"BrkComm\",\n",
    "        \"BrkFace\",\n",
    "        \"CBlock\",\n",
    "        \"CemntBd\",\n",
    "        \"HdBoard\",\n",
    "        \"ImStucc\",\n",
    "        \"MetalSd\",\n",
    "        \"Other\",\n",
    "        \"Plywood\",\n",
    "        \"PreCast\",\n",
    "        \"Stone\",\n",
    "        \"Stucco\",\n",
    "        \"VinylSd\",\n",
    "        \"Wd Sdng\",\n",
    "        \"WdShing\",\n",
    "    ],\n",
    "    \"Exterior2nd\": [\n",
    "        \"AsbShng\",\n",
    "        \"AsphShn\",\n",
    "        \"BrkComm\",\n",
    "        \"BrkFace\",\n",
    "        \"CBlock\",\n",
    "        \"CemntBd\",\n",
    "        \"HdBoard\",\n",
    "        \"ImStucc\",\n",
    "        \"MetalSd\",\n",
    "        \"Other\",\n",
    "        \"Plywood\",\n",
    "        \"PreCast\",\n",
    "        \"Stone\",\n",
    "        \"Stucco\",\n",
    "        \"VinylSd\",\n",
    "        \"Wd Sdng\",\n",
    "        \"WdShing\",\n",
    "    ],\n",
    "    \"MasVnrType\": [\"BrkCmn\", \"BrkFace\", \"CBlock\", \"Stone\", \"None\"],\n",
    "    \"Foundation\": [\"BrkTil\", \"CBlock\", \"PConc\", \"Slab\", \"Stone\", \"Wood\"],\n",
    "    \"Heating\": [\"Floor\", \"GasA\", \"GasW\", \"Grav\", \"OthW\", \"Wall\"],\n",
    "    \"CentralAir\": [\"N\", \"Y\"],\n",
    "    \"GarageType\": [\n",
    "        \"2Types\",\n",
    "        \"Attchd\",\n",
    "        \"Basment\",\n",
    "        \"BuiltIn\",\n",
    "        \"CarPort\",\n",
    "        \"Detchd\",\n",
    "        \"None\",\n",
    "    ],\n",
    "    \"MiscFeature\": [\"Elev\", \"Gar2\", \"Othr\", \"Shed\", \"TenC\", \"None\"],\n",
    "    \"SaleType\": [\n",
    "        \"WD\",\n",
    "        \"CWD\",\n",
    "        \"VWD\",\n",
    "        \"New\",\n",
    "        \"COD\",\n",
    "        \"Con\",\n",
    "        \"ConLw\",\n",
    "        \"ConLI\",\n",
    "        \"ConLD\",\n",
    "        \"Oth\",\n",
    "    ],\n",
    "    \"SaleCondition\": [\"Normal\", \"Abnorml\", \"AdjLand\", \"Alloca\", \"Family\", \"Partial\"],\n",
    "}\n",
    "\n",
    "# Ordered categorical columns\n",
    "five_levels = [\"Po\", \"Fa\", \"TA\", \"Gd\", \"Ex\"]\n",
    "six_levels = [\"None\", \"Po\", \"Fa\", \"TA\", \"Gd\", \"Ex\"]\n",
    "ten_levels = list(range(1, 11))\n",
    "\n",
    "ordered_levels = {\n",
    "    \"OverallQual\": ten_levels,\n",
    "    \"OverallCond\": ten_levels,\n",
    "    \"ExterQual\": five_levels,\n",
    "    \"ExterCond\": five_levels,\n",
    "    \"BsmtQual\": six_levels,\n",
    "    \"BsmtCond\": six_levels,\n",
    "    \"HeatingQC\": five_levels,\n",
    "    \"KitchenQual\": five_levels,\n",
    "    \"FireplaceQu\": six_levels,\n",
    "    \"GarageQual\": six_levels,\n",
    "    \"GarageCond\": six_levels,\n",
    "    \"PoolQC\": [\"None\", \"Fa\", \"TA\", \"Gd\", \"Ex\"],\n",
    "    \"LotShape\": [\"Reg\", \"IR1\", \"IR2\", \"IR3\"],\n",
    "    \"LandSlope\": [\"Sev\", \"Mod\", \"Gtl\"],\n",
    "    \"BsmtExposure\": [\"None\", \"No\", \"Mn\", \"Av\", \"Gd\"],\n",
    "    \"BsmtFinType1\": [\"None\", \"Unf\", \"LwQ\", \"Rec\", \"BLQ\", \"ALQ\", \"GLQ\"],\n",
    "    \"BsmtFinType2\": [\"None\", \"Unf\", \"LwQ\", \"Rec\", \"BLQ\", \"ALQ\", \"GLQ\"],\n",
    "    \"Functional\": [\"Sal\", \"Sev\", \"Maj1\", \"Maj2\", \"Mod\", \"Min2\", \"Min1\", \"Typ\"],\n",
    "    \"GarageFinish\": [\"None\", \"Unf\", \"RFn\", \"Fin\"],\n",
    "    \"PavedDrive\": [\"N\", \"P\", \"Y\"],\n",
    "    \"Utilities\": [\"ELO\", \"NoSeWa\", \"NoSewr\", \"AllPub\"],\n",
    "    \"Electrical\": [\"Mix\", \"FuseP\", \"FuseF\", \"FuseA\", \"SBrkr\"],\n",
    "    \"Fence\": [\"None\", \"MnWw\", \"GdWo\", \"MnPrv\", \"GdPrv\"],\n",
    "}\n",
    "\n",
    "\n",
    "ordered_cols = list(ordered_levels.keys())\n",
    "unordered_cols = list(unordered_levels.keys())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To perform these categorization, the class CategorizeNominal was created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 865,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class CategorizeNominal\n",
    "class CategorizeNominal:\n",
    "    def __init__(self, ordered_levels, unordered_levels):\n",
    "        self.ordered_levels = ordered_levels\n",
    "        self.unordered_levels = unordered_levels\n",
    "\n",
    "    def __repr__(self):\n",
    "        return \"CategorizeNominal()\"\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        self.X = X.copy()\n",
    "\n",
    "        for col, levels in self.unordered_levels.items():\n",
    "            self.X[col] = self.X[col].astype(CategoricalDtype(levels))\n",
    "        for col, levels in self.ordered_levels.items():\n",
    "            self.X[col] = self.X[col].astype(CategoricalDtype(levels, ordered=True))\n",
    "\n",
    "        return self.X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before feeding a model with data, all values must be numeric, so I'll use the class EncodeNominal to convert strings in columns to the numeric equivalent level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 866,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class EncodeCategories\n",
    "class EncodeCategories:\n",
    "    def __init__(self):\n",
    "        return None\n",
    "\n",
    "    def __repr__(self):\n",
    "        return \"EncodeCategories()\"\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        self.X = X.copy()\n",
    "\n",
    "        for colname in self.X.select_dtypes([\"category\"]):\n",
    "            self.X[colname] = self.X[colname].cat.codes\n",
    "        return self.X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.3 Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 867,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classes FillWith, FillByKNN, FillByGroup\n",
    "class FillWith:\n",
    "\n",
    "    \"\"\"\n",
    "    Fill a list of cols with a specified value\n",
    "\n",
    "    >>> df = {'col1': [1, 2, NaN], 'col2': [4, 5, 6], 'col3': [7, NaN, 10]}\n",
    "    >>> filler = FillWith(['col1', 'col2'], -1)\n",
    "    >>> df_filled = filler.transform(df)\n",
    "\n",
    "    >>> df_filled\n",
    "       col1  col2 col3\n",
    "    0     1     4    7\n",
    "    1     2     5   -1\n",
    "    2    -1     6   10\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, cols=[], value=\"None\"):\n",
    "        self.cols = cols\n",
    "        self.value = value\n",
    "\n",
    "    def __repr__(self):\n",
    "        return \"FillWith(cols=%s, value=%s)\" % (self.cols, self.value)\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        self.X = X.copy()\n",
    "        self.X[self.cols] = self.X[self.cols].fillna(self.value)\n",
    "        return self.X\n",
    "\n",
    "\n",
    "class FillByKNN:\n",
    "    def __init__(self, n_neighbors=5, targets=None, keyword=None):\n",
    "        self.n_neighbors = n_neighbors\n",
    "        self.targets = targets\n",
    "        self.keyword = keyword\n",
    "        self.cols = None\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def __repr__(self):\n",
    "        return \"FillByKNN(n_neighbors=%i, targets=%s, keyword=%s,cols=%s)\" % (\n",
    "            self.n_neighbors,\n",
    "            self.targets,\n",
    "            self.keyword,\n",
    "            self.cols,\n",
    "        )\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "\n",
    "        self.X = X.copy()\n",
    "\n",
    "        # If 'keyword' is none, use all the columns to estimate the KNN\n",
    "        # else, use just columns that match the 'keyword'\n",
    "        if self.keyword is None:\n",
    "            self.cols_ = [col for col in self.X.columns]\n",
    "        else:\n",
    "            self.cols_ = [col for col in self.X.columns if self.keyword in col]\n",
    "\n",
    "        # If 'targets' is none, use select all columns with missing value to fill\n",
    "        if self.targets is None:\n",
    "            self.targets_ = list(self.X.columns[self.X.isnull().any()])\n",
    "            if self.keyword is not None:\n",
    "                self.cols_ = list(set(self.targets + self.cols))\n",
    "        else:\n",
    "            self.targets_ = self.targets\n",
    "\n",
    "        self.mapper = {}\n",
    "        # Find each categorical column passed as arguments 'cols' and convert to numeric\n",
    "        for col in self.cols_:\n",
    "            if X[col].dtypes == \"object\" or X[col].dtypes == \"category\":\n",
    "                # replace 'object' columns to 'numeric' versions and store nominal value in mapper\n",
    "                # to reverse the transformation.\n",
    "                self.X.loc[:, col], self.mapper[col] = self.X.loc[:, col].factorize()\n",
    "\n",
    "        # Input missing values with KNNImputer\n",
    "        self.imputer = KNNImputer(n_neighbors=self.n_neighbors)\n",
    "        self.result = pd.DataFrame(\n",
    "            self.imputer.fit_transform(self.X[self.cols_]),\n",
    "            columns=self.cols_,\n",
    "            index=self.X.index,\n",
    "        )\n",
    "\n",
    "        # Update targets with imputed data\n",
    "        self.X.loc[:, self.targets_] = self.result[self.targets_]\n",
    "\n",
    "        # Reverse to categorical values\n",
    "        for col, unique in self.mapper.items():\n",
    "            try:\n",
    "                self.X.loc[:, col] = unique[self.X[col].astype(int)]\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                pass\n",
    "\n",
    "        return self.X\n",
    "\n",
    "\n",
    "class FillByGroup:\n",
    "\n",
    "    \"\"\"\n",
    "    Group columns and fill based on a reference col.\n",
    "\n",
    "    >>> df = {'HasCar': [NaN, 1, 1, NaN], 'CarMotor': [NaN, 2, 3, 4], 'CarWheelSize':[NaN, NaN, Large, NaN] 'Bike': [5, 6, 7, 8]}\n",
    "    >>> filler = FillByGroup(group_ref = 'HasCar', group_keyword = 'Car', num_value= 0, cat_values = 'None')\n",
    "    >>> df_filled = filler.transform(df)\n",
    "\n",
    "    >>> df_filled\n",
    "       HasCar  CarMotor CarWheelSize Bike\n",
    "    0       0         0         None    5\n",
    "    1       1         2          NaN    6\n",
    "    2       1         3        Large    7\n",
    "    3       0         4         None    8\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, group_ref=None, group_keyword=None, num_value=0, cat_value=\"None\"\n",
    "    ):\n",
    "\n",
    "        self.group_ref = group_ref\n",
    "        self.group_keyword = group_keyword\n",
    "        self.num_value = num_value\n",
    "        self.cat_value = cat_value\n",
    "\n",
    "    def __repr__(self):\n",
    "        return (\n",
    "            \"FillByGroup(group_ref=%s, group_keyword=%s, num_value=%i, cat_value=%s)\"\n",
    "            % (self.group_ref, self.group_keyword, self.num_value, self.cat_value)\n",
    "        )\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "\n",
    "        self.X = X.copy()\n",
    "        self.cols = [col for col in self.X.columns if self.group_keyword in col]\n",
    "        self.null_mask = pd.isnull(self.X[self.group_ref])\n",
    "\n",
    "        # split 'object' (str) and 'numeric' (int, float) columns\n",
    "        self.num_cols = list(X[self.cols].select_dtypes(\"number\").columns)\n",
    "        self.object_cols = list(X[self.cols].select_dtypes(\"category\").columns) + list(\n",
    "            X[self.cols].select_dtypes(\"object\").columns\n",
    "        )\n",
    "\n",
    "        self.X.loc[self.null_mask, self.num_cols] = self.X.loc[\n",
    "            self.null_mask, self.num_cols\n",
    "        ].fillna(self.num_value)\n",
    "\n",
    "        self.X.loc[self.null_mask, self.object_cols] = self.X.loc[\n",
    "            self.null_mask, self.object_cols\n",
    "        ].fillna(self.cat_value)\n",
    "\n",
    "        return self.X\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As shown by [missing plot](#missing_data), the dataset has some missing values. Most data is missing because the feature doesn't exist, like a house that doesn't have **Pool**, **Alley**, **Fence**, **Basement**, or a **Garage**. \n",
    "\n",
    "To fill these data i'll use the class FillWith(). These columns will be filled with **None**\n",
    "\n",
    "        FillWith(cols=['PoolQC', 'MiscFeature','Alley', 'Fence', 'FireplaceQu'], value='None')\n",
    "\n",
    "The same occurs to Garage, MasVnr, and Bsmt data, but it these, each feature has a set of columns, so I'll use the class FillByGroup(). This class use as a parameter a column responsible for saying whether the house has the feature or not and a keyword used to find all columns corresponding to that feature (with similar names). These columns will be filled with '0' when numerical, and 'None' when categorical\n",
    "\n",
    "        FillByGroup(group_ref='GarageType', group_keyword='Garage', cat_value='None')\\\n",
    "        FillByGroup(group_ref='BsmtCond', group_keyword='Bsmt', cat_value='None')\\\n",
    "        FillByGroup(group_ref='MasVnrType', group_keyword='MasVnr', cat_value='None')\n",
    "\n",
    "Finally, the remaining missing columns will be filled using the class FillByKNN()\n",
    "\n",
    "        FillByKNN(n_neighbors=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.4 Type Mismatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 868,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Class ConvertToInt\n",
    "class ConvertToInt:\n",
    "    def __init__(self, cols):\n",
    "        self.cols_ = cols\n",
    "\n",
    "    def is_int(self, col):\n",
    "        return np.array_equal(self.X[col], self.X[col].astype(int))\n",
    "\n",
    "    def __repr__(self):\n",
    "        return \"ConvertToInt()\"\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        self.X = X.copy()\n",
    "        for col in self.cols_:\n",
    "            if self.is_int(col):\n",
    "                self.X[col] = self.X[col].astype(int)\n",
    "        return self.X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some columns have different dtypes between train and test data. This may be an issue when performing feature engineering, so I'll use the class ConvertToInt to fix this mismatch.\n",
    "\n",
    "    ConvertToInt(cols=['BsmtFinSF1','BsmtFinSF2','BsmtUnfSF','TotalBsmtSF',\n",
    "                       'BsmtFullBath','BsmtHalfBath','GarageCars','GarageArea'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 869,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>BsmtFinSF2</th>\n",
       "      <th>BsmtUnfSF</th>\n",
       "      <th>TotalBsmtSF</th>\n",
       "      <th>BsmtFullBath</th>\n",
       "      <th>BsmtHalfBath</th>\n",
       "      <th>GarageCars</th>\n",
       "      <th>GarageArea</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>706</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>856</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>978</td>\n",
       "      <td>0</td>\n",
       "      <td>284</td>\n",
       "      <td>1262</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>460</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    BsmtFinSF1  BsmtFinSF2  BsmtUnfSF  TotalBsmtSF  BsmtFullBath  \\\n",
       "Id                                                                 \n",
       "1          706           0        150          856             1   \n",
       "2          978           0        284         1262             0   \n",
       "\n",
       "    BsmtHalfBath  GarageCars  GarageArea  \n",
       "Id                                        \n",
       "1              0           2         548  \n",
       "2              1           2         460  "
      ]
     },
     "execution_count": 869,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.loc[:, X_test.dtypes != X.dtypes].head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 870,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>BsmtFinSF2</th>\n",
       "      <th>BsmtUnfSF</th>\n",
       "      <th>TotalBsmtSF</th>\n",
       "      <th>BsmtFullBath</th>\n",
       "      <th>BsmtHalfBath</th>\n",
       "      <th>GarageCars</th>\n",
       "      <th>GarageArea</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1461</th>\n",
       "      <td>468.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>270.0</td>\n",
       "      <td>882.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>730.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1462</th>\n",
       "      <td>923.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>406.0</td>\n",
       "      <td>1329.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>312.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      BsmtFinSF1  BsmtFinSF2  BsmtUnfSF  TotalBsmtSF  BsmtFullBath  \\\n",
       "Id                                                                   \n",
       "1461       468.0       144.0      270.0        882.0           0.0   \n",
       "1462       923.0         0.0      406.0       1329.0           0.0   \n",
       "\n",
       "      BsmtHalfBath  GarageCars  GarageArea  \n",
       "Id                                          \n",
       "1461           0.0         1.0       730.0  \n",
       "1462           0.0         1.0       312.0  "
      ]
     },
     "execution_count": 870,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.loc[:, X_test.dtypes != X.dtypes].head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, I'll define a baseline to the model, this baseline will be made only using the data preparation steps above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 871,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a copy of data\n",
    "X_train, y_train = X.copy(), y.copy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 Base Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 872,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base pipeline\n",
    "fix_typos = FixTypos()\n",
    "\n",
    "categorize_nominal = CategorizeNominal(ordered_levels, unordered_levels)\n",
    "encode_nominal = EncodeCategories()\n",
    "\n",
    "fill = make_pipeline(\n",
    "    FillByGroup(group_ref=\"GarageType\", group_keyword=\"Garage\"),\n",
    "    FillByGroup(group_ref=\"BsmtCond\", group_keyword=\"Bsmt\"),\n",
    "    FillByGroup(group_ref=\"MasVnrType\", group_keyword=\"MasVnr\"),\n",
    "    FillWith(\n",
    "        cols=[\"PoolQC\", \"MiscFeature\", \"Alley\", \"Fence\", \"FireplaceQu\"], value=\"None\"\n",
    "    ),\n",
    "    FillByKNN(n_neighbors=1),\n",
    ")\n",
    "\n",
    "convert_to_int = ConvertToInt(\n",
    "    cols=[\n",
    "        \"BsmtFinSF1\",\n",
    "        \"BsmtFinSF2\",\n",
    "        \"BsmtUnfSF\",\n",
    "        \"TotalBsmtSF\",\n",
    "        \"BsmtFullBath\",\n",
    "        \"BsmtHalfBath\",\n",
    "        \"GarageCars\",\n",
    "        \"GarageArea\",\n",
    "    ]\n",
    ")\n",
    "\n",
    "base_pipeline = make_pipeline(fix_typos, categorize_nominal, fill, encode_nominal, convert_to_int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 873,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_base = base_pipeline.fit_transform(X_train)\n",
    "X_test_base = base_pipeline.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 Score Baseline Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 874,
   "metadata": {},
   "outputs": [],
   "source": [
    "# score_dataset function\n",
    "def score_dataset(X, y, model=XGBRegressor()):\n",
    "    X = X.copy()\n",
    "    # Metric for Housing competition is RMSLE (Root Mean Squared Log Error)\n",
    "    log_y = np.log(y)\n",
    "    scores = np.sqrt(-cross_val_score(model, X, log_y, cv=5, scoring=\"neg_mean_squared_error\"))\n",
    "    return scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 875,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13801466578140298"
      ]
     },
     "execution_count": 875,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_model = XGBRegressor()\n",
    "score_base = score_dataset(X_train_base, y_train, baseline_model)\n",
    "score_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 876,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate_submission_file\n",
    "def create_submission_file(name, y_pred, score):\n",
    "    # Concatenate the predictions in a dataset\n",
    "    output = pd.DataFrame(y_pred, index=np.arange(1461,2920), columns=[\"SalePrice\"])\n",
    "\n",
    "    output[\"Id\"] = output.index\n",
    "\n",
    "    # Generate a file name with datetime info\n",
    "    file_name = datetime.datetime.today().strftime(\n",
    "        f\"%Y_%m_%d__%H_%M_%S_scored__{np.round(score,6)}\"\n",
    "    )\n",
    "    # Generate the submission file\n",
    "    output.to_csv(f\"output/{name}_{file_name}__.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 877,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_model.fit(X_train_base, y_train)\n",
    "y_pred_base = baseline_model.predict(X_test_base)\n",
    "create_submission_file(\"baseline\",y_pred_base, score_base)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1 Mathematical, Countings, Grouping, and Interactions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build some features can improve our model perfomance, let's test some new variables.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 878,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class BuildMathFeatures, BuildInteractionsFeatures, BuildGroupFeatures\n",
    "class BuildMathFeatures:\n",
    "    def __init__(self):\n",
    "        return None\n",
    "\n",
    "    def __repr__(self):\n",
    "        return \"BuildMathFeatures()\"\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        self.X = X.copy()\n",
    "        self.X[\"TotalFlrSF\"] = self.X.FirstFlrSF + self.X.SecondFlrSF\n",
    "        self.X[\"LivLotRatio\"] = self.X.GrLivArea / self.X.LotArea\n",
    "        self.X[\"LivRmRatio\"] = self.X.GrLivArea / self.X.TotRmsAbvGrd\n",
    "        self.X[\"Spaciouness\"] = self.X.FirstFlrSF + self.X.SecondFlrSF / self.X.TotRmsAbvGrd\n",
    "\n",
    "        return self.X\n",
    "\n",
    "\n",
    "class BuildInteractionsFeatures:\n",
    "    def __init__(self):\n",
    "        self.enc1 = OneHotEncoder(sparse=False, handle_unknown=\"ignore\")\n",
    "        self.enc2 = OneHotEncoder(sparse=False, handle_unknown=\"ignore\")\n",
    "        self.enc3 = OneHotEncoder(sparse=False, handle_unknown=\"ignore\")\n",
    "        self.enc4 = OneHotEncoder(sparse=False, handle_unknown=\"ignore\")\n",
    "        self.enc5 = OneHotEncoder(sparse=False, handle_unknown=\"ignore\")\n",
    "\n",
    "        return None\n",
    "\n",
    "    def __repr__(self):\n",
    "        return \"BuildInteractionsFeatures()\"\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        self.enc1.fit(X[[\"BedroomAbvGr\"]])\n",
    "        self.enc2.fit(X[[\"BldgType\"]])\n",
    "        self.enc3.fit(X[[\"GarageCars\"]])\n",
    "        self.enc4.fit(X[[\"BsmtCond\"]])\n",
    "        self.enc5.fit(X[[\"KitchenAbvGr\"]])\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        self.X = X.copy()\n",
    "\n",
    "        X1 = self.enc1.transform(self.X[[\"BedroomAbvGr\"]])\n",
    "        X1 = pd.DataFrame(\n",
    "            X1, columns=list(self.enc1.get_feature_names_out()), index=self.X.index\n",
    "        )\n",
    "        X1 = X1.mul(self.X.GrLivArea, axis=0)\n",
    "\n",
    "        X2 = self.enc2.transform(self.X[[\"BldgType\"]])\n",
    "        X2 = pd.DataFrame(\n",
    "            X2, columns=list(self.enc2.get_feature_names_out()), index=self.X.index\n",
    "        )\n",
    "        X2 = X2.mul(self.X.GrLivArea, axis=0)\n",
    "\n",
    "            \n",
    "        X3 = self.enc3.transform(self.X[[\"GarageCars\"]])\n",
    "        X3 = pd.DataFrame(\n",
    "            X3, columns=list(self.enc3.get_feature_names_out()), index=self.X.index\n",
    "        )\n",
    "        X3 = X3.mul(self.X.GrLivArea, axis=0)\n",
    "\n",
    "\n",
    "        X4 = self.enc4.transform(self.X[[\"BsmtCond\"]])\n",
    "        X4 = pd.DataFrame(\n",
    "            X4, columns=list(self.enc4.get_feature_names_out()), index=self.X.index\n",
    "        )\n",
    "        X4 = X4.mul(self.X.TotalBsmtSF, axis=0)\n",
    "\n",
    "        X5 = self.enc5.transform(self.X[[\"KitchenAbvGr\"]])\n",
    "        X5 = pd.DataFrame(\n",
    "            X5, columns=list(self.enc5.get_feature_names_out()), index=self.X.index\n",
    "        )\n",
    "        X5 = X5.mul(self.X.GrLivArea, axis=0)\n",
    "\n",
    "        self.X = pd.concat([self.X, X1], axis=1)\n",
    "        return self.X\n",
    "\n",
    "\n",
    "class BuildCountsFeatures:\n",
    "    def __init__(self):\n",
    "        return None\n",
    "\n",
    "    def __repr__(self):\n",
    "        return \"BuildCountsFeatures()\"\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        self.X = X.copy()\n",
    "        self.X[\"Compartments\"] = (\n",
    "            self.X[\"TotRmsAbvGrd\"] + self.X[\"KitchenAbvGr\"] + self.X[\"FullBath\"]\n",
    "        )\n",
    "        self.X[\"TotalFullBaths\"] = self.X[\"BsmtFullBath\"] + self.X[\"FullBath\"]\n",
    "        self.X[\"TotalHalfBaths\"] = self.X[\"BsmtHalfBath\"] + self.X[\"HalfBath\"]\n",
    "        return self.X\n",
    "\n",
    "\n",
    "class BuildGroupFeatures:\n",
    "    def __init__(self):\n",
    "        return None\n",
    "\n",
    "    def __repr__(self):\n",
    "        return \"BuildGroupFeatures()\"\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        self.X = X.copy()\n",
    "        self.X[\"Neigh_Area_mean\"] = self.X.groupby(\"Neighborhood\")[\"LotArea\"].transform(\n",
    "            \"mean\"\n",
    "        )\n",
    "        self.X[\"BedRm_LvArea_mean\"] = self.X.groupby(\"BedroomAbvGr\")[\"GrLivArea\"].transform(\"mean\")\n",
    "\n",
    "        # new\n",
    "        # self.X[\"Neigh_Area_mean\"] = self.X.groupby(\"Neighborhood\")[\"LotFrontage\"].transform(\"mean\")\n",
    "        return self.X\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Create features by **Matematical** operations between other columns in the dataset.\n",
    "\n",
    "**Interactions** will expand the relationship between each category in a column and the target variables.\n",
    "\n",
    "**Counts** features are columns generated by counting values from another column, or by counting features through other columns. \n",
    "\n",
    "Finnaly, **Group** features will group one features by another."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 879,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_math_feat = BuildMathFeatures()\n",
    "add_interactions_feat = BuildInteractionsFeatures()\n",
    "add_count_feat = BuildCountsFeatures()\n",
    "add_group_feat = BuildGroupFeatures()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 Standardizing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.2.1 Standardize Sale Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 880,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_distribuition, plot_dist_norm\n",
    "def plot_distribuition(var):\n",
    "    fig, ax = plt.subplots(1,2, figsize=(9, 3))\n",
    "\n",
    "    skew_var = var.skew()\n",
    "    kurt_var = var.kurt()\n",
    "    g1 = sns.histplot(var, kde=True,color=\"#225480\", ax=ax[0]);\n",
    "\n",
    "    plt.legend(['Dist. (Skew = {:.2f}, Kurtoise = {:.2f} )'.format(skew_var, kurt_var)],\n",
    "                loc='best')\n",
    "                \n",
    "    qqplot(var, line='s', ax=ax[1])\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    ax[0].set_ylabel(\"Frequency\")\n",
    "    ax[0].set_title(\"SalePrice distribution\")\n",
    "    ax[1].set_title('Quantile-Quantile')\n",
    "\n",
    "def plot_dist_norm(var_n):\n",
    "    fig, ax = plt.subplots(1,2, figsize=(9, 3))\n",
    "\n",
    "    sns.histplot(var_n , kde=True, color=\"#207b7d\", ax=ax[0]);\n",
    "    (mu, sigma) = norm.fit(var_n)\n",
    "\n",
    "    qqplot(var_n, line='s', ax=ax[1])\n",
    "\n",
    "    ax[0].set_ylabel(\"Frequency\")\n",
    "    ax[0].set_title(\"SalePrice distribution\")\n",
    "    ax[1].set_title('Quantile-Quantile')\n",
    "\n",
    "    ax[0].legend(['Normal dist. ($\\mu=$ {:.2f} and $\\sigma=$ {:.2f} )'.format(mu, sigma)],\n",
    "                loc='best')\n",
    "\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some algorithms benefit from normally distributed data, hence the non-normally distributed data will be transformed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 881,
   "metadata": {},
   "outputs": [],
   "source": [
    "if PLOT:\n",
    "    plot_distribuition(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In comparison with a normal curve, this data is right-skewed, and the positive kurtosis indicates a more tapered and concentrated curve, which too indicated fewer outliers.\n",
    "\n",
    "From the q-q plot we can infer that the data are not normal, as if they were the points would fall approximately on the red line.Being more rigorous and using a statistical test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 882,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p = 2.28385e-133\n",
      "'null hypothesis': data distribuition is normal\n",
      "The 'null hypothesis' can be rejected\n"
     ]
    }
   ],
   "source": [
    "k2, p = normaltest(y_train)\n",
    "alpha = 1e-3\n",
    "print(\"p = {:g}\".format(p))\n",
    "print(\"'null hypothesis': data distribuition is normal\")\n",
    "if p < alpha:  # null hypothesis: x comes from a normal distribution\n",
    "    print(\"The 'null hypothesis' can be rejected\")\n",
    "else:\n",
    "    print(\"The null hypothesis cannot be rejected\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "normalize the target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 883,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_n = np.log1p(y_train)\n",
    "if PLOT:\n",
    "    plot_dist_norm(y_train_n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.2.2 Standardize Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 884,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class StandardizeFeatures\n",
    "class StandardizeFeatures:\n",
    "    def __init__(self, skewed_cols):\n",
    "        self.cols = skewed_cols\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        self.X = X.copy()\n",
    "        self.X[self.cols]\n",
    "        try:\n",
    "            self.X[self.cols] = self.X[self.cols].apply(\n",
    "                lambda x: boxcox1p(x, boxcox_normmax(x + 1)), axis=0\n",
    "            )\n",
    "            return self.X\n",
    "        except Exception as e:\n",
    "            print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 885,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_numbers = X_train_base.drop(unordered_cols + ordered_cols, axis=1)\n",
    "filter_skewed = (df_numbers.skew() > 0.5) & (df_numbers.nunique() > 100)\n",
    "skewd_feat = filter_skewed[filter_skewed].index\n",
    "\n",
    "if PLOT:\n",
    "    melted_df = pd.melt(\n",
    "        X_train_base[skewd_feat],\n",
    "        var_name='column'\n",
    "    )\n",
    "    g = sns.FacetGrid(melted_df, col='column', col_wrap=5, sharex=False, sharey=False, height=2)\n",
    "    g.map(sns.histplot, 'value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 886,
   "metadata": {},
   "outputs": [],
   "source": [
    "skewed_cols = [\n",
    "    \"LotFrontage\",\n",
    "    \"LotArea\",\n",
    "    \"MasVnrArea\",\n",
    "    \"BsmtFinSF1\",\n",
    "    \"BsmtFinSF2\",\n",
    "    \"BsmtUnfSF\",\n",
    "    \"TotalBsmtSF\",\n",
    "    \"FirstFlrSF\",\n",
    "    \"SecondFlrSF\",\n",
    "    \"GrLivArea\",\n",
    "    \"WoodDeckSF\",\n",
    "    \"OpenPorchSF\",\n",
    "    \"EnclosedPorch\",\n",
    "]\n",
    "\n",
    "standardize_feat = StandardizeFeatures(skewed_cols=skewed_cols)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  5. K-means clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 887,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class BuildCluster\n",
    "class BuildCluster:\n",
    "    def __init__(self, cols, n_clusters, n_init=50, name=\"Cluster\"):\n",
    "        self.cols = cols\n",
    "        self.n_clusters = n_clusters\n",
    "        self.n_init = n_init\n",
    "        self.name = name\n",
    "\n",
    "    def __repr__(self):\n",
    "        return \"BuildGroupFeatures(cols=%s, n_clusters=%s, n_init=%i, name=%s)\" % (\n",
    "            self.cols,\n",
    "            self.n_clusters,\n",
    "            self.n_init,\n",
    "            self.name,\n",
    "        )\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        self.X = X.copy()\n",
    "\n",
    "        # select a set of columns to perform clustering\n",
    "        self.X_cols = self.X[self.cols].copy()\n",
    "\n",
    "        # convert any categorical variable to numerical\n",
    "        for colname in self.X_cols.select_dtypes([\"category\"]):\n",
    "            self.X_cols[colname] = self.X_cols[colname].cat.codes\n",
    "\n",
    "        self.X_cols = self.X_cols.astype(int)\n",
    "\n",
    "        # scale the data set\n",
    "        self.X_scaled = (self.X_cols - self.X_cols.mean(axis=0)) / self.X_cols.std(\n",
    "            axis=0\n",
    "        )  \n",
    "        \n",
    "        # perform the fitting\n",
    "        self.kmeans = KMeans(\n",
    "            n_clusters=self.n_clusters, n_init=self.n_init, random_state=0\n",
    "        )\n",
    "\n",
    "        self.X[self.name] = self.kmeans.fit_predict(self.X_scaled)\n",
    "        self.X[self.name] = self.X[self.name].astype(\"category\")\n",
    "\n",
    "        return self.X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can group data points by similarity using clustering and use the clusters to see how much our model improves.\n",
    "I'll use data from house characteristics like, roof style, roof material, mansory veneer type, foundation etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1 Search the best number of clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 888,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search Best K\n",
    "def search_best_k(df, targets, cols, trials):\n",
    "    best_score = 100\n",
    "    for k in range(1, trials):\n",
    "        add_cluster = BuildCluster(cols, k, 50, name=\"Cluster1\")\n",
    "        df_with_cluster = add_cluster.transform(df)\n",
    "        \n",
    "        score = score_dataset(df_with_cluster, targets)\n",
    "        if score < best_score:\n",
    "            best_score = score\n",
    "            print(\">\", end=\"\")\n",
    "        print(f\"{k}, {score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 889,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' variables = [\"RoofStyle\", \"RoofMatl\"]\\nsearch_best_k(X_train_base, y_train, variables, 21) '"
      ]
     },
     "execution_count": 889,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" variables = [\"RoofStyle\", \"RoofMatl\"]\n",
    "search_best_k(X_train_base, y_train, variables, 21) \"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are some scores found and variables that was used\n",
    "|n_clusters| variables |\n",
    "| --- |  --- |\n",
    "| 4   | [\"RoofStyle\", \"RoofMatl\",\"MasVnrType\"]|\n",
    "|11   | [\"RoofStyle\", \"RoofMatl\",\"Exterior1st\" , \"MasVnrType\", \"ExterCond\", \"ExterQual\", \"Foundation\"] |\n",
    "|15   | [\"RoofStyle\", \"RoofMatl\"] |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2 Create pipeline to add cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the class BuildCluster that add a cluster column to the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 890,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = [\n",
    "    \"RoofStyle\",\n",
    "    \"RoofMatl\",\n",
    "    \"Exterior2nd\",\n",
    "    \"MasVnrType\",\n",
    "    \"ExterCond\",\n",
    "    \"ExterQual\",\n",
    "    \"Foundation\",\n",
    "]\n",
    "add_cluster = BuildCluster(variables, 8, 50, name=\"Cluster1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Principal Component Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 891,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class BuildPCA\n",
    "class BuildPCA:\n",
    "    def __init__(self, cols, drop_originals=False, use_n_components=None):\n",
    "        self._cols = cols\n",
    "        self._pca = None\n",
    "        self._X_pca = None\n",
    "        self._loadings = None\n",
    "        self._drop_originals = drop_originals\n",
    "        self._use_n_components = use_n_components\n",
    "\n",
    "    def __repr__(self):\n",
    "        return \"BuildPCA(cols=%s)\" % (self._cols)\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        \n",
    "        self.X = X.copy()\n",
    "\n",
    "        self._pca, self._X_pca, self._loadings = self._apply_pca(self.X, self._cols)\n",
    "\n",
    "        if self._use_n_components:\n",
    "            self._X_pca = self._X_pca.iloc[:, : self._use_n_components]\n",
    "\n",
    "        self.X = pd.concat([self.X, self._X_pca], axis=1)\n",
    "\n",
    "        if self._drop_originals:\n",
    "            self.X = self.X.drop(self._cols, axis=1)\n",
    "        return self.X\n",
    "\n",
    "    def _apply_pca(self, X, features):\n",
    "\n",
    "        X = X.loc[:, features]\n",
    "\n",
    "        for colname in X.select_dtypes([\"category\"]):\n",
    "            X[colname] = X[colname].cat.codes\n",
    "\n",
    "        X_scaled = (X - X.mean(axis=0)) / X.std(axis=0)\n",
    "\n",
    "        pca = PCA()\n",
    "        X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "        component_names = [f\"PC{i+1}\" for i in range(X_pca.shape[1])]\n",
    "\n",
    "        X_pca = pd.DataFrame(X_pca, columns=component_names, index=X_scaled.index)\n",
    "\n",
    "        loadings = pd.DataFrame(\n",
    "            pca.components_.T,  # transpose the matrix of loadings\n",
    "            columns=component_names,  # so the columns are the principal components\n",
    "            index=X.columns,  # and the rows are the original features\n",
    "        )\n",
    "\n",
    "        return pca, X_pca, loadings\n",
    "\n",
    "    def get_variables(self):\n",
    "        return self._cols\n",
    "\n",
    "    def get_x_pca(self):\n",
    "        return self._X_pca\n",
    "\n",
    "    def get_pca(self):\n",
    "        return self._pca\n",
    "\n",
    "    def get_loadings(self):\n",
    "        return self._loadings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PCA is a dimensionality-reduction method that helps to reduce the number of variables of a data set by transform _p_ variables into _k_ principal components, then often a _k_ < _p_ will store the most of the variation of _p_ variables.\n",
    "\n",
    "When we have a large number of correlated variables in a data set, we can reduce to just a few principal componets with still explain the most of the variance of the original variables.\n",
    "\n",
    "Also, because we just keep the principal components, the main of the information is kept, and the noise is removed.\n",
    "\n",
    "A less number of variables transform makes our model more computationally efficient."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.1 Selecting High correlated variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 892,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Exterior1st   Exterior2nd     0.870791\n",
       "Exterior2nd   Exterior1st     0.870791\n",
       "TotalBsmtSF   FirstFlrSF      0.819530\n",
       "FirstFlrSF    TotalBsmtSF     0.819530\n",
       "GrLivArea     TotRmsAbvGrd    0.825489\n",
       "TotRmsAbvGrd  GrLivArea       0.825489\n",
       "Fireplaces    FireplaceQu     0.863241\n",
       "FireplaceQu   Fireplaces      0.863241\n",
       "GarageYrBlt   GarageQual      0.946629\n",
       "              GarageCond      0.949411\n",
       "GarageCars    GarageArea      0.882475\n",
       "GarageArea    GarageCars      0.882475\n",
       "GarageQual    GarageYrBlt     0.946629\n",
       "              GarageCond      0.959172\n",
       "GarageCond    GarageYrBlt     0.949411\n",
       "              GarageQual      0.959172\n",
       "PoolArea      PoolQC          0.899924\n",
       "PoolQC        PoolArea        0.899924\n",
       "dtype: float64"
      ]
     },
     "execution_count": 892,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Thank you @mikkom from stackoverflow to that piece of code\n",
    "corr = X_train_base.select_dtypes('number').corr().stack()\n",
    "\n",
    "# Ignore autocorrelation\n",
    "corr = corr[corr.index.get_level_values(0) != corr.index.get_level_values(1)]\n",
    "\n",
    "# Select only highly correlated (ρ => 0.8)\n",
    "high_corr = corr[corr > 0.8]\n",
    "high_corr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 893,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Exterior1st', 'Exterior2nd', 'TotalBsmtSF', 'FirstFlrSF', 'GrLivArea',\n",
       "       'TotRmsAbvGrd', 'Fireplaces', 'FireplaceQu', 'GarageYrBlt',\n",
       "       'GarageCars', 'GarageArea', 'GarageQual', 'GarageCond', 'PoolArea',\n",
       "       'PoolQC'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 893,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Parse to a list\n",
    "high_corr_variables = high_corr.index.unique(level=0)\n",
    "high_corr_variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.2 Create Pipeline to add PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With PCA we can either, substitute the original variables by computed PCA's and discard less informative variables, use loadings to inspire combination of variables. I choose the first option.\n",
    "\n",
    "Passing a argument _drop_originals=True_, the transformed variables will be used instead of the original, and the _use_n_components=n_ will define the number of PCA used ( PC1, PC2,...,PCn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 894,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_pca = BuildPCA(high_corr_variables, drop_originals=True, use_n_components=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 895,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_pca = make_pipeline(base_pipeline, add_pca)\n",
    "X_train_pca = pipe_pca.fit_transform(X_train)\n",
    "\n",
    "pca = pipe_pca[1].get_pca()\n",
    "\n",
    "if PLOT:\n",
    "    plot_variance(pca)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Targeting Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 896,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class CrossFoldEncoder\n",
    "class CrossFoldEncoder:\n",
    "    def __init__(self, encoder, cols, **kwargs):\n",
    "        self.encoder_ = encoder\n",
    "        self.kwargs_ = kwargs  # keyword arguments for the encoder\n",
    "        self.cv_ = KFold(n_splits=5)\n",
    "        self.cols = cols\n",
    "\n",
    "    # Fit an encoder on one split and transform the feature on the\n",
    "    # other. Iterating over the splits in all folds gives a complete\n",
    "    # transformation. We also now have one trained encoder on each\n",
    "    # fold.\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def fit_transform(self, X, y):\n",
    "        self.fitted_encoders_ = []\n",
    "        X_encoded = []\n",
    "        for idx_encode, idx_train in self.cv_.split(X):\n",
    "            fitted_encoder = self.encoder_(cols=self.cols, **self.kwargs_)\n",
    "            fitted_encoder.fit(\n",
    "                X.iloc[idx_encode, :],\n",
    "                y.iloc[idx_encode],\n",
    "            )\n",
    "            X_encoded.append(fitted_encoder.transform(X.iloc[idx_train, :])[self.cols])\n",
    "            self.fitted_encoders_.append(fitted_encoder)\n",
    "        X_encoded = pd.concat(X_encoded)\n",
    "        X_encoded.columns = [name + \"_encoded\" for name in X_encoded.columns]\n",
    "        return X.join(X_encoded)\n",
    "\n",
    "    # To transform the test data, average the encodings learned from\n",
    "    # each fold.\n",
    "    def transform(self, X):\n",
    "        from functools import reduce\n",
    "\n",
    "        X_encoded_list = []\n",
    "        for fitted_encoder in self.fitted_encoders_:\n",
    "            X_encoded = fitted_encoder.transform(X)\n",
    "            X_encoded_list.append(X_encoded[self.cols])\n",
    "        X_encoded = reduce(lambda x, y: x.add(y, fill_value=0), X_encoded_list) / len(\n",
    "            X_encoded_list\n",
    "        )\n",
    "        X_encoded.columns = [name + \"_encoded\" for name in X_encoded.columns]\n",
    "        return X.join(X_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 897,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['MSSubClass', 'LotFrontage', 'Neighborhood', 'YearBuilt',\n",
       "       'YearRemodAdd', 'Exterior1st', 'Exterior2nd', 'BsmtFinSF2',\n",
       "       'LowQualFinSF', 'TotRmsAbvGrd', 'GarageYrBlt', 'OpenPorchSF',\n",
       "       'EnclosedPorch', 'Threeseasonporch', 'ScreenPorch', 'MiscVal',\n",
       "       'MoSold'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 897,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "low_cadinality = (X_train_base.nunique() > 10) & (X_train_base.nunique() < 250) \n",
    "target_enc_cols = low_cadinality[low_cadinality].index\n",
    "target_enc_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 898,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_encoder = CrossFoldEncoder(CatBoostEncoder , cols=[\"ScreenPorch\", \"Neighborhood\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 899,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe_cols = [\n",
    "    \"MSSubClass\",\n",
    "    \"MSZoning\",\n",
    "    \"Street\",\n",
    "    \"Alley\",\n",
    "    \"LotShape\",\n",
    "    \"LandContour\",\n",
    "    \"Utilities\",\n",
    "    \"LotConfig\",\n",
    "    \"LandSlope\",\n",
    "    \"Neighborhood\",\n",
    "    \"Condition1\",\n",
    "    \"Condition2\",\n",
    "    \"BldgType\",\n",
    "    \"HouseStyle\",\n",
    "    \"OverallCond\",\n",
    "    \"RoofStyle\",\n",
    "    \"RoofMatl\",\n",
    "    \"MasVnrType\",\n",
    "    \"ExterQual\",\n",
    "    \"ExterCond\",\n",
    "    \"Foundation\",\n",
    "    \"BsmtQual\",\n",
    "    \"BsmtCond\",\n",
    "    \"BsmtExposure\",\n",
    "    \"BsmtFinType1\",\n",
    "    \"BsmtFinType2\",\n",
    "    \"Heating\",\n",
    "    \"CentralAir\",\n",
    "    \"Electrical\",\n",
    "    \"KitchenQual\",\n",
    "    \"Functional\",\n",
    "    \"GarageType\",\n",
    "    \"GarageFinish\",\n",
    "    \"PavedDrive\",\n",
    "    \"Fence\",\n",
    "    \"MiscFeature\",\n",
    "    \"MoSold\",\n",
    "    \"SaleType\",\n",
    "    \"SaleCondition\",\n",
    "]\n",
    "\n",
    "ohe = make_column_transformer(\n",
    "    (\n",
    "        OneHotEncoder(sparse=False, handle_unknown=\"ignore\"),\n",
    "        ohe_cols,\n",
    "    ),\n",
    "    remainder=\"passthrough\",\n",
    "    verbose_feature_names_out=False,\n",
    ")\n",
    "\n",
    "final_pipeline = make_pipeline(\n",
    "    base_pipeline,\n",
    "    add_math_feat,\n",
    "    convert_to_int,\n",
    "    add_interactions_feat,\n",
    "    add_count_feat,\n",
    "    #add_group_feat,\n",
    "    #add_cluster,\n",
    "    #add_pca,\n",
    "    # target_encoder,\n",
    "    ohe,\n",
    ")\n",
    "\n",
    "X_train_final = final_pipeline.fit_transform(X_train, y_train)\n",
    "X_test_final = final_pipeline.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 900,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_final_df = pd.DataFrame(X_train_final, columns=final_pipeline[-1].get_feature_names_out())\n",
    "X_test_final_df = pd.DataFrame(X_test_final, columns=final_pipeline[-1].get_feature_names_out())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.2 Filter using RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 901,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from os.path import exists, isdir\n",
    "\n",
    "\n",
    "if not exists(\"models/rfe_sel.pkl\"):\n",
    "\n",
    "    from sklearn.feature_selection import RFECV\n",
    "    rfe_sel = RFECV(XGBRegressor(), min_features_to_select=80, step=2)\n",
    "    rfe_sel.fit(X_train_final_df, y_train_n) \n",
    "\n",
    "    with open('models/rfe_sel.pkl', 'wb') as file:\n",
    "        pickle.dump(rfe_sel, file)\n",
    "else:\n",
    "    with open('models/rfe_sel.pkl', 'rb') as file:\n",
    "        rfe_sel = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 902,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_rfe = rfe_sel.transform(X_train_final_df)\n",
    "X_test_rfe = rfe_sel.transform(X_test_final_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 944,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_set, X_holdout_set, y_train_set, y_holdout_set = train_test_split(X_train_rfe, y_train_n, train_size=0.65)\n",
    "X_dev_set, X_test_set, y_dev_set, y_test_set = train_test_split(X_holdout_set, y_holdout_set, test_size=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 945,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((949, 83), (306, 83), (205, 83))"
      ]
     },
     "execution_count": 945,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_set.shape, X_dev_set.shape, X_test_set.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 946,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.linear_model import ElasticNet, Lasso, BayesianRidge, LassoLarsIC\n",
    "from sklearn.ensemble import RandomForestRegressor,  GradientBoostingRegressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 947,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optuna Objectives\n",
    "import optuna\n",
    "\n",
    "\n",
    "def objective_krr(trial):\n",
    "    model_params = dict(\n",
    "        alpha=trial.suggest_float(\"alpha\", 0.1, 1.0),\n",
    "        kernel=trial.suggest_categorical(\n",
    "            \"kernel\", [\"linear\", \"polynomial\", \"laplacian\"]\n",
    "        ),\n",
    "        gamma=trial.suggest_float(\"gamma\", 0.1, 1.0),\n",
    "        degree=trial.suggest_int(\"degree\", 3, 15),\n",
    "        coef0=trial.suggest_float(\"coef0\", 1, 15),\n",
    "    )\n",
    "\n",
    "    model = KernelRidge(**model_params)\n",
    "    model.fit(X_train_set, y_train_set)\n",
    "    y_pred = model.predict(X_dev_set)\n",
    "    return rmsle(y_dev_set, y_pred)\n",
    "\n",
    "def objective_bsr(trial):\n",
    "    model_params = dict(\n",
    "        n_iter=trial.suggest_int(\"n_iter\", 300, 8000),\n",
    "        tol=trial.suggest_float(\"tol\", 1e-6, 1e-1, log=True),\n",
    "        alpha_1=trial.suggest_float(\"alpha_1\", 1e-6, 1e-1, log=True),\n",
    "        alpha_2=trial.suggest_float(\"alpha_2\", 1e-6, 1e-1, log=True),\n",
    "        lambda_1=trial.suggest_float(\"lambda_1\", 1e-6, 1e-1, log=True),\n",
    "        lambda_2=trial.suggest_float(\"lambda_1\", 1e-6, 1e-1, log=True),\n",
    "    )\n",
    "    model = make_pipeline(RobustScaler(), BayesianRidge(**model_params))\n",
    "    model.fit(X_train_set, y_train_set)\n",
    "    y_pred = model.predict(X_dev_set)\n",
    "    return rmsle(y_dev_set, y_pred)\n",
    "\n",
    "def objective_en(trial):\n",
    "    model_params = dict(\n",
    "        alpha=trial.suggest_float(\"alpha\", 0.0, 1.0),\n",
    "        l1_ratio=trial.suggest_float(\"tol\", 1e-6, 1e-1, log=True),\n",
    "        max_iter=trial.suggest_int(\"max_iter\", 200, 5000),\n",
    "        tol=trial.suggest_float(\"tol\", 1e-6, 1e-1, log=True),\n",
    "        selection=trial.suggest_categorical(\"selection\", [\"cyclic\", \"random\"]),\n",
    "    )\n",
    "    model = make_pipeline(RobustScaler(), ElasticNet(**model_params))\n",
    "    model.fit(X_train_set, y_train_set)\n",
    "    y_pred = model.predict(X_dev_set)\n",
    "    return rmsle(y_dev_set, y_pred)\n",
    "\n",
    "def objective_ls(trial):\n",
    "    model_params = dict(\n",
    "        alpha=trial.suggest_float(\"alpha\", 0.0, 1.0),\n",
    "        max_iter=trial.suggest_int(\"max_iter\", 200, 5000),\n",
    "        tol=trial.suggest_float(\"tol\", 1e-6, 1e-1, log=True),\n",
    "        selection=trial.suggest_categorical(\"selection\", [\"cyclic\", \"random\"]),\n",
    "    )\n",
    "\n",
    "    model = make_pipeline(RobustScaler(), ElasticNet(**model_params))\n",
    "    model.fit(X_train_set, y_train_set)\n",
    "    y_pred = model.predict(X_dev_set)\n",
    "    return rmsle(y_dev_set, y_pred)\n",
    "\n",
    "def objective_xgb(trial):\n",
    "    model_params = dict(\n",
    "        max_depth=trial.suggest_int(\"max_depth\", 2, 10),\n",
    "        learning_rate=trial.suggest_float(\"learning_rate\", 1e-4, 1e-1, log=True),\n",
    "        gamma=trial.suggest_float(\"gamma\", 0.0, 1.0),\n",
    "        n_estimators=trial.suggest_int(\"n_estimators\", 100, 2000),\n",
    "        min_child_weight=trial.suggest_int(\"min_child_weight\", 1, 10),\n",
    "        colsample_bytree=trial.suggest_float(\"colsample_bytree\", 0.2, 1.0),\n",
    "        subsample=trial.suggest_float(\"subsample\", 0.2, 1.0),\n",
    "        reg_alpha=trial.suggest_float(\"reg_alpha\", 1e-4, 1e2, log=True),\n",
    "        reg_lambda=trial.suggest_float(\"reg_lambda\", 1e-4, 1e2, log=True),\n",
    "    )\n",
    "\n",
    "    model = XGBRegressor(**model_params)\n",
    "    model.fit(X_train_set, y_train_set)\n",
    "    y_pred = model.predict(X_dev_set)\n",
    "    return rmsle(y_dev_set, y_pred)\n",
    "\n",
    "def objective_lgb(trial):\n",
    "    model_params = dict(\n",
    "        max_depth=trial.suggest_int(\"max_depth\", 2, 10),\n",
    "        learning_rate=trial.suggest_float(\"learning_rate\", 1e-4, 1e-1, log=True),\n",
    "        n_estimators=trial.suggest_int(\"n_estimators\", 100, 2000),\n",
    "        #min_child_weight=trial.suggest_int(\"min_child_weight\", 1, 10),\n",
    "        colsample_bytree=trial.suggest_float(\"colsample_bytree\", 0.2, 1.0),\n",
    "        subsample=trial.suggest_float(\"subsample\", 0.2, 1.0),\n",
    "        #reg_alpha=trial.suggest_float(\"reg_alpha\", 1e-4, 1e2, log=True),\n",
    "        #reg_lambda=trial.suggest_float(\"reg_lambda\", 1e-4, 1e2, log=True),\n",
    "    )\n",
    "\n",
    "    model = LGBMRegressor(**model_params)\n",
    "    model.fit(X_train_set, y_train_set)\n",
    "    y_pred = model.predict(X_dev_set)\n",
    "    return rmsle(y_dev_set, y_pred)\n",
    "\n",
    "def objective_gb(trial):\n",
    "    model_params = dict(\n",
    "        #loss=trial.suggest_categorical(\"loss\", ['squared_error', 'absolute_error', 'huber', 'quantile']),\n",
    "        learning_rate=trial.suggest_float(\"learning_rate\", 0.001, 0.1, log=True),\n",
    "        n_estimators=trial.suggest_int(\"n_estimators\", 100, 2000),\n",
    "        subsample=trial.suggest_float(\"subsample\", 0.2, 1.0),\n",
    "        #min_samples_split=trial.suggest_int(\"min_samples_split\", 2, 20),\n",
    "        #min_samples_leaf=trial.suggest_int(\"min_samples_leaf\", 1, 10),\n",
    "        #min_weight_fraction_leaf=trial.suggest_float(\"min_weight_fraction_leaf\", 0.0, 0.2),\n",
    "        max_depth=trial.suggest_int(\"max_depth\", 2, 10),\n",
    "    )\n",
    "\n",
    "    model = GradientBoostingRegressor(**model_params)\n",
    "    model.fit(X_train_set, y_train_set)\n",
    "    y_pred = model.predict(X_dev_set)\n",
    "    return rmsle(y_dev_set, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 948,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRIES = 1000\n",
    "# Optuna Studies\n",
    "if not exists(\"models/krr_study.pkl\"):\n",
    "\n",
    "    krr_study = optuna.create_study(direction=\"minimize\")\n",
    "    krr_study.optimize(objective_krr, n_trials=2*TRIES)\n",
    "\n",
    "    with open('models/krr_study.pkl', 'wb') as file:\n",
    "        pickle.dump(krr_study, file)\n",
    "\n",
    "if not exists(\"models/ls_study.pkl\"):\n",
    "\n",
    "    ls_study = optuna.create_study(direction=\"minimize\")\n",
    "    ls_study.optimize(objective_ls, n_trials=2*TRIES)\n",
    "\n",
    "    with open('models/ls_study.pkl', 'wb') as file:\n",
    "        pickle.dump(ls_study, file)\n",
    "    \n",
    "if not exists(\"models/en_study.pkl\"):\n",
    "\n",
    "    en_study = optuna.create_study(direction=\"minimize\")\n",
    "    en_study.optimize(objective_en, n_trials=2*TRIES)\n",
    "\n",
    "    with open('models/en_study.pkl', 'wb') as file:\n",
    "        pickle.dump(en_study, file)\n",
    "    \n",
    "if not exists(\"models/bsr_study.pkl\"):\n",
    "\n",
    "    bsr_study = optuna.create_study(direction=\"minimize\")\n",
    "    bsr_study.optimize(objective_bsr, n_trials=2*TRIES)\n",
    "\n",
    "    with open('models/bsr_study.pkl', 'wb') as file:\n",
    "        pickle.dump(bsr_study, file)\n",
    "\n",
    "if not exists(\"models/gb_study.pkl\"):\n",
    "\n",
    "    gb_study = optuna.create_study(direction=\"minimize\")\n",
    "    gb_study.optimize(objective_gb, n_trials=0.4*TRIES)\n",
    "\n",
    "    with open('models/gb_study.pkl', 'wb') as file:\n",
    "        pickle.dump(gb_study, file)\n",
    "\n",
    "if not exists(\"models/xgb_study.pkl\"):\n",
    "\n",
    "    xgb_study = optuna.create_study(direction=\"minimize\")\n",
    "    xgb_study.optimize(objective_xgb, n_trials=0.4*TRIES)\n",
    "\n",
    "    with open('models/xgb_study.pkl', 'wb') as file:\n",
    "        pickle.dump(xgb_study, file)\n",
    "\n",
    "if not exists(\"models/lgb_study.pkl\"):\n",
    "\n",
    "    lgb_study = optuna.create_study(direction=\"minimize\")\n",
    "    lgb_study.optimize(objective_lgb, n_trials=0.4*TRIES)\n",
    "\n",
    "    with open('models/lgb_study.pkl', 'wb') as file:\n",
    "        pickle.dump(lgb_study, file)\n",
    "\n",
    "\n",
    "with open('models/krr_study.pkl', 'rb') as file:\n",
    "    krr_study = pickle.load(file)\n",
    "\n",
    "with open('models/ls_study.pkl', 'rb') as file:\n",
    "    ls_study = pickle.load(file)\n",
    "\n",
    "with open('models/en_study.pkl', 'rb') as file:\n",
    "    en_study = pickle.load(file)\n",
    "\n",
    "with open('models/bsr_study.pkl', 'rb') as file:\n",
    "    bsr_study = pickle.load(file)\n",
    "\n",
    "with open('models/gb_study.pkl', 'rb') as file:\n",
    "    gb_study = pickle.load(file)\n",
    "\n",
    "with open('models/lgb_study.pkl', 'rb') as file:\n",
    "    lgb_study = pickle.load(file)\n",
    "\n",
    "with open('models/xgb_study.pkl', 'rb') as file:\n",
    "    xgb_study = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 949,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12031774454454237\n",
      "0.1231105686845313\n",
      "0.11720846490647342\n",
      "0.11783487376069886\n",
      "0.1149981763304335\n",
      "0.1157720830039523\n",
      "0.12539376210532752\n"
     ]
    }
   ],
   "source": [
    "print(bsr_study.best_value)\n",
    "print(krr_study.best_value)\n",
    "print(en_study.best_value)\n",
    "print(ls_study.best_value)\n",
    "print(gb_study.best_value)\n",
    "print(xgb_study.best_value)\n",
    "print(lgb_study.best_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 965,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingRegressor\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "\n",
    "\n",
    "KRR_model = KernelRidge(**krr_study.best_params)\n",
    "BSR_model = make_pipeline(RobustScaler(), BayesianRidge(**bsr_study.best_params))\n",
    "EN_model = make_pipeline(RobustScaler(), ElasticNet(**en_study.best_params))\n",
    "LS_model = make_pipeline(RobustScaler(), Lasso(**ls_study.best_params))\n",
    "GB_model = GradientBoostingRegressor(**gb_study.best_params)\n",
    "XGB_model = XGBRegressor(**xgb_study.best_params)\n",
    "LGB_model = LGBMRegressor(**lgb_study.best_params)\n",
    "\n",
    "estimators = [\n",
    "    #(\"BSR\", BSR_model),\n",
    "    (\"KRR\", KRR_model),\n",
    "    (\"EN\", EN_model),\n",
    "    (\"LS\", LS_model),\n",
    "    (\"GB\", GB_model),\n",
    "    #(\"XGB\", XGB_model),\n",
    "    #(\"LGB\", LGB_model),\n",
    "]\n",
    "\n",
    "voting_reg = VotingRegressor(estimators, n_jobs=2)\n",
    "\n",
    "staking_reg = StackingRegressor(estimators, final_estimator=Lasso(alpha=0.005))\n",
    "\n",
    "estimators2 = [\n",
    "    (\"staking\", staking_reg),\n",
    "    (\"BSR\", KRR_model),\n",
    "    (\"XGB\", XGB_model),\n",
    "    (\"LGB\", LGB_model),\n",
    "\n",
    "]\n",
    "\n",
    "blending_reg = VotingRegressor(estimators2, weights=[0.5, 0.15, 0.2, 0.15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 966,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-8073cf3d-2503-42cb-a77a-2066b2b67f2e {color: black;background-color: white;}#sk-8073cf3d-2503-42cb-a77a-2066b2b67f2e pre{padding: 0;}#sk-8073cf3d-2503-42cb-a77a-2066b2b67f2e div.sk-toggleable {background-color: white;}#sk-8073cf3d-2503-42cb-a77a-2066b2b67f2e label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-8073cf3d-2503-42cb-a77a-2066b2b67f2e div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-8073cf3d-2503-42cb-a77a-2066b2b67f2e div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-8073cf3d-2503-42cb-a77a-2066b2b67f2e input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-8073cf3d-2503-42cb-a77a-2066b2b67f2e div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-8073cf3d-2503-42cb-a77a-2066b2b67f2e div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-8073cf3d-2503-42cb-a77a-2066b2b67f2e input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-8073cf3d-2503-42cb-a77a-2066b2b67f2e div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-8073cf3d-2503-42cb-a77a-2066b2b67f2e div.sk-estimator:hover {background-color: #d4ebff;}#sk-8073cf3d-2503-42cb-a77a-2066b2b67f2e div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-8073cf3d-2503-42cb-a77a-2066b2b67f2e div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-8073cf3d-2503-42cb-a77a-2066b2b67f2e div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 2em;bottom: 0;left: 50%;}#sk-8073cf3d-2503-42cb-a77a-2066b2b67f2e div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;}#sk-8073cf3d-2503-42cb-a77a-2066b2b67f2e div.sk-item {z-index: 1;}#sk-8073cf3d-2503-42cb-a77a-2066b2b67f2e div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;}#sk-8073cf3d-2503-42cb-a77a-2066b2b67f2e div.sk-parallel::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 2em;bottom: 0;left: 50%;}#sk-8073cf3d-2503-42cb-a77a-2066b2b67f2e div.sk-parallel-item {display: flex;flex-direction: column;position: relative;background-color: white;}#sk-8073cf3d-2503-42cb-a77a-2066b2b67f2e div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-8073cf3d-2503-42cb-a77a-2066b2b67f2e div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-8073cf3d-2503-42cb-a77a-2066b2b67f2e div.sk-parallel-item:only-child::after {width: 0;}#sk-8073cf3d-2503-42cb-a77a-2066b2b67f2e div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;position: relative;}#sk-8073cf3d-2503-42cb-a77a-2066b2b67f2e div.sk-label label {font-family: monospace;font-weight: bold;background-color: white;display: inline-block;line-height: 1.2em;}#sk-8073cf3d-2503-42cb-a77a-2066b2b67f2e div.sk-label-container {position: relative;z-index: 2;text-align: center;}#sk-8073cf3d-2503-42cb-a77a-2066b2b67f2e div.sk-container {display: inline-block;position: relative;}</style><div id=\"sk-8073cf3d-2503-42cb-a77a-2066b2b67f2e\" class\"sk-top-container\"><div class=\"sk-container\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"25512b15-a930-459b-bf1c-7e4ebcf37dfe\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"25512b15-a930-459b-bf1c-7e4ebcf37dfe\">VotingRegressor</label><div class=\"sk-toggleable__content\"><pre>VotingRegressor(estimators=[('staking',\n",
       "                             StackingRegressor(estimators=[('KRR',\n",
       "                                                            KernelRidge(alpha=0.9999780372789604,\n",
       "                                                                        coef0=8.224775687698992,\n",
       "                                                                        degree=15,\n",
       "                                                                        gamma=0.5309871990102119)),\n",
       "                                                           ('EN',\n",
       "                                                            Pipeline(steps=[('robustscaler',\n",
       "                                                                             RobustScaler()),\n",
       "                                                                            ('elasticnet',\n",
       "                                                                             ElasticNet(alpha=0.008211687246427346,\n",
       "                                                                                        max_iter=266,\n",
       "                                                                                        tol=0.08117387109770938))])),\n",
       "                                                           ('LS',\n",
       "                                                            Pipeline(steps=[('robu...\n",
       "                                          reg_alpha=0.0012736829472204834,\n",
       "                                          reg_lambda=0.17775900869906144,\n",
       "                                          scale_pos_weight=None,\n",
       "                                          subsample=0.6910791123768263,\n",
       "                                          tree_method=None,\n",
       "                                          validate_parameters=None,\n",
       "                                          verbosity=None)),\n",
       "                            ('LGB',\n",
       "                             LGBMRegressor(colsample_bytree=0.3578535412811334,\n",
       "                                           learning_rate=0.02242198331475503,\n",
       "                                           max_depth=3, n_estimators=1167,\n",
       "                                           subsample=0.5056784923374928))],\n",
       "                weights=[0.5, 0.15, 0.2, 0.15])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>staking</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>KRR</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"00b22889-15ac-4837-a562-07ded2c0ad09\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"00b22889-15ac-4837-a562-07ded2c0ad09\">KernelRidge</label><div class=\"sk-toggleable__content\"><pre>KernelRidge(alpha=0.9999780372789604, coef0=8.224775687698992, degree=15,\n",
       "            gamma=0.5309871990102119)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>EN</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"e7248ac1-ac3b-44fb-8c00-239fd4420ff0\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"e7248ac1-ac3b-44fb-8c00-239fd4420ff0\">RobustScaler</label><div class=\"sk-toggleable__content\"><pre>RobustScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"90ccdcb0-dab2-46b8-a162-62f448ad96c1\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"90ccdcb0-dab2-46b8-a162-62f448ad96c1\">ElasticNet</label><div class=\"sk-toggleable__content\"><pre>ElasticNet(alpha=0.008211687246427346, max_iter=266, tol=0.08117387109770938)</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>LS</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"adee256c-c6e5-400e-b88d-1fc25e509ad5\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"adee256c-c6e5-400e-b88d-1fc25e509ad5\">RobustScaler</label><div class=\"sk-toggleable__content\"><pre>RobustScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"4e70db57-a2f2-40a1-b734-3450b3bbebbe\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"4e70db57-a2f2-40a1-b734-3450b3bbebbe\">Lasso</label><div class=\"sk-toggleable__content\"><pre>Lasso(alpha=0.0020380536369776605, max_iter=2006, selection='random',\n",
       "      tol=0.00011304357580572231)</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>GB</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"7317f205-e4c7-47a4-ba34-5f33fd166536\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"7317f205-e4c7-47a4-ba34-5f33fd166536\">GradientBoostingRegressor</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingRegressor(learning_rate=0.01144370459810913, max_depth=4,\n",
       "                          n_estimators=1965, subsample=0.3265337181044042)</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>final_estimator</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"3e3812c0-6997-4fb0-b3cf-c7d5c53ea475\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"3e3812c0-6997-4fb0-b3cf-c7d5c53ea475\">Lasso</label><div class=\"sk-toggleable__content\"><pre>Lasso(alpha=0.005)</pre></div></div></div></div></div></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>BSR</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"df16cb4b-4a8c-4746-b17f-2361a553c0c9\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"df16cb4b-4a8c-4746-b17f-2361a553c0c9\">KernelRidge</label><div class=\"sk-toggleable__content\"><pre>KernelRidge(alpha=0.9999780372789604, coef0=8.224775687698992, degree=15,\n",
       "            gamma=0.5309871990102119)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>XGB</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"c2e7ab38-eb13-472f-89d6-212564b31bb4\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"c2e7ab38-eb13-472f-89d6-212564b31bb4\">XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
       "             colsample_bynode=None, colsample_bytree=0.6845304386246804,\n",
       "             enable_categorical=False, gamma=0.006695906171062173, gpu_id=None,\n",
       "             importance_type=None, interaction_constraints=None,\n",
       "             learning_rate=0.03721283489205575, max_delta_step=None,\n",
       "             max_depth=10, min_child_weight=4, missing=nan,\n",
       "             monotone_constraints=None, n_estimators=723, n_jobs=None,\n",
       "             num_parallel_tree=None, predictor=None, random_state=None,\n",
       "             reg_alpha=0.0012736829472204834, reg_lambda=0.17775900869906144,\n",
       "             scale_pos_weight=None, subsample=0.6910791123768263,\n",
       "             tree_method=None, validate_parameters=None, verbosity=None)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>LGB</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"7bb59140-79cf-48a1-a9be-66436222b214\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"7bb59140-79cf-48a1-a9be-66436222b214\">LGBMRegressor</label><div class=\"sk-toggleable__content\"><pre>LGBMRegressor(colsample_bytree=0.3578535412811334,\n",
       "              learning_rate=0.02242198331475503, max_depth=3, n_estimators=1167,\n",
       "              subsample=0.5056784923374928)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "VotingRegressor(estimators=[('staking',\n",
       "                             StackingRegressor(estimators=[('KRR',\n",
       "                                                            KernelRidge(alpha=0.9999780372789604,\n",
       "                                                                        coef0=8.224775687698992,\n",
       "                                                                        degree=15,\n",
       "                                                                        gamma=0.5309871990102119)),\n",
       "                                                           ('EN',\n",
       "                                                            Pipeline(steps=[('robustscaler',\n",
       "                                                                             RobustScaler()),\n",
       "                                                                            ('elasticnet',\n",
       "                                                                             ElasticNet(alpha=0.008211687246427346,\n",
       "                                                                                        max_iter=266,\n",
       "                                                                                        tol=0.08117387109770938))])),\n",
       "                                                           ('LS',\n",
       "                                                            Pipeline(steps=[('robu...\n",
       "                                          reg_alpha=0.0012736829472204834,\n",
       "                                          reg_lambda=0.17775900869906144,\n",
       "                                          scale_pos_weight=None,\n",
       "                                          subsample=0.6910791123768263,\n",
       "                                          tree_method=None,\n",
       "                                          validate_parameters=None,\n",
       "                                          verbosity=None)),\n",
       "                            ('LGB',\n",
       "                             LGBMRegressor(colsample_bytree=0.3578535412811334,\n",
       "                                           learning_rate=0.02242198331475503,\n",
       "                                           max_depth=3, n_estimators=1167,\n",
       "                                           subsample=0.5056784923374928))],\n",
       "                weights=[0.5, 0.15, 0.2, 0.15])"
      ]
     },
     "execution_count": 966,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#staking_reg.fit(X_train_set, y_train_set)\n",
    "#voting_reg.fit(X_train_set, y_train_set)\n",
    "blending_reg.fit(X_train_set, y_train_set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 967,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11131270193922718"
      ]
     },
     "execution_count": 967,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_model = blending_reg\n",
    "\n",
    "final_score = rmsle(y_test_set, final_model.predict(X_test_set))\n",
    "final_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 968,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([129389.01909706, 158014.77825814, 182640.61860576, ...,\n",
       "       167043.23267676, 115837.86988533, 225727.55183227])"
      ]
     },
     "execution_count": 968,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_model.fit(X_train_rfe, y_train_n)\n",
    "y_pred = np.expm1(final_model.predict(X_test_rfe))\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 954,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_submission_file(\"final\", y_pred, final_score)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "728b8f97ad7b66a77e7c0c3bc7fafe5e1ae8325e3c6903c8fc266752a3321bc0"
  },
  "kernelspec": {
   "display_name": "Python 3.8.0 64-bit ('portifolio': virtualenv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
